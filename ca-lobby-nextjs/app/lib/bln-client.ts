/**
 * BLN (California Campaign Finance Data) Client Integration
 *
 * This module provides integration with the BLN API for downloading
 * California campaign finance data, similar to the Python bln package.
 * Migrated from Bignewdownload_2.py functionality.
 */

import { executeQuery, uploadToBigQuery } from './bigquery-client'

// BLN API Configuration
export interface BLNConfig {
  apiKey: string
  projectId: string
  baseUrl?: string
  timeout?: number
}

// California Campaign Finance Data Tables
export const BLN_DATA_TABLES = {
  // Cover page data
  cvr_lobby_disclosure_cd: {
    name: 'CVR Lobby Disclosure',
    description: 'Lobbying disclosure cover page information',
    category: 'disclosure'
  },
  cvr_registration_cd: {
    name: 'CVR Registration',
    description: 'Lobbyist registration cover page information',
    category: 'registration'
  },

  // Payment and compensation data
  lpay_cd: {
    name: 'Lobbyist Payments',
    description: 'Payments to lobbyists',
    category: 'payments'
  },
  latt_cd: {
    name: 'Lobbyist Associations',
    description: 'Payments to lobbying associations',
    category: 'payments'
  },

  // Activity and employment data
  lccm_cd: {
    name: 'Lobbying Contacts',
    description: 'Lobbying contacts and communications',
    category: 'activity'
  },
  lemp_cd: {
    name: 'Lobbyist Employment',
    description: 'Lobbyist employment information',
    category: 'employment'
  },
  lexp_cd: {
    name: 'Lobbying Expenses',
    description: 'Lobbying expenses',
    category: 'expenses'
  },
  loth_cd: {
    name: 'Other Lobbying Payments',
    description: 'Other lobbying-related payments',
    category: 'payments'
  },

  // Reference data
  filername_cd: {
    name: 'Filer Names',
    description: 'Filer name reference data',
    category: 'reference'
  }
} as const

export type BLNTableName = keyof typeof BLN_DATA_TABLES

export interface BLNDownloadResult {
  success: boolean
  tableName: string
  data?: any[]
  rowCount?: number
  downloadedAt: string
  fromCache?: boolean
  error?: string
  metadata?: {
    lastModified?: string
    version?: string
    dataQuality?: number
  }
}

export interface BLNBulkDownloadResult {
  success: boolean
  results: BLNDownloadResult[]
  totalTables: number
  successfulDownloads: number
  failedDownloads: number
  totalRows: number
  downloadTime: number
  errors: string[]
}

/**
 * BLN Client for California Campaign Finance Data
 */
export class BLNClient {
  private config: BLNConfig
  private cache: Map<string, { data: any[]; timestamp: number; ttl: number }> = new Map()

  constructor(config: BLNConfig) {
    this.config = {
      baseUrl: 'https://api.bln.gov/ca-campaign-finance', // Placeholder URL
      timeout: 30000,
      ...config
    }

    if (!this.config.apiKey) {
      throw new Error('BLN API key is required')
    }

    if (!this.config.projectId) {
      throw new Error('BLN project ID is required')
    }
  }

  /**
   * Download a specific table from BLN API
   */
  async downloadTable(
    tableName: BLNTableName,
    options: {
      useCache?: boolean
      cacheTimeout?: number
      includeMetadata?: boolean
    } = {}
  ): Promise<BLNDownloadResult> {
    const { useCache = true, cacheTimeout = 3600000, includeMetadata = false } = options
    const startTime = Date.now()

    try {
      console.log(`üì• Downloading BLN table: ${tableName}`)

      // Check cache first
      const cacheKey = `bln:${tableName}`
      if (useCache && this.cache.has(cacheKey)) {
        const cached = this.cache.get(cacheKey)!
        if (Date.now() - cached.timestamp < cached.ttl) {
          console.log(`üíæ Cache hit for table: ${tableName}`)
          return {
            success: true,
            tableName,
            data: cached.data,
            rowCount: cached.data.length,
            downloadedAt: new Date().toISOString(),
            fromCache: true
          }
        } else {
          this.cache.delete(cacheKey)
        }
      }

      // For production, this would make actual API calls to BLN
      // For now, we'll simulate the download with mock data similar to the original Python script
      const mockData = await this.simulateBLNDownload(tableName)

      if (!mockData.success) {
        return {
          success: false,
          tableName,
          downloadedAt: new Date().toISOString(),
          error: mockData.error
        }
      }

      // Cache the result
      if (useCache) {
        this.cache.set(cacheKey, {
          data: mockData.data!,
          timestamp: Date.now(),
          ttl: cacheTimeout
        })
      }

      const result: BLNDownloadResult = {
        success: true,
        tableName,
        data: mockData.data,
        rowCount: mockData.data!.length,
        downloadedAt: new Date().toISOString(),
        fromCache: false
      }

      if (includeMetadata) {
        result.metadata = {
          lastModified: new Date().toISOString(),
          version: '1.0',
          dataQuality: 95.5
        }
      }

      console.log(`‚úÖ Downloaded ${tableName}: ${result.rowCount} rows in ${Date.now() - startTime}ms`)

      return result

    } catch (error) {
      console.error(`‚ùå Failed to download ${tableName}:`, error)

      return {
        success: false,
        tableName,
        downloadedAt: new Date().toISOString(),
        error: error instanceof Error ? error.message : 'Unknown download error'
      }
    }
  }

  /**
   * Download multiple tables in parallel (similar to Bignewdownload_2.py bulk logic)
   */
  async downloadTables(
    tableNames: BLNTableName[],
    options: {
      concurrency?: number
      useCache?: boolean
      includeMetadata?: boolean
      onProgress?: (completed: number, total: number) => void
    } = {}
  ): Promise<BLNBulkDownloadResult> {
    const { concurrency = 3, useCache = true, includeMetadata = false, onProgress } = options
    const startTime = Date.now()

    console.log(`üöÄ Starting bulk download of ${tableNames.length} tables`)

    const results: BLNDownloadResult[] = []
    const errors: string[] = []
    let totalRows = 0

    // Process tables in batches to respect concurrency limits
    for (let i = 0; i < tableNames.length; i += concurrency) {
      const batch = tableNames.slice(i, i + concurrency)

      const batchPromises = batch.map(tableName =>
        this.downloadTable(tableName, { useCache, includeMetadata })
      )

      try {
        const batchResults = await Promise.all(batchPromises)
        results.push(...batchResults)

        // Update progress
        if (onProgress) {
          onProgress(results.length, tableNames.length)
        }

      } catch (error) {
        const errorMsg = `Batch ${Math.floor(i / concurrency) + 1} failed: ${error instanceof Error ? error.message : 'Unknown error'}`
        errors.push(errorMsg)
        console.error(`‚ùå ${errorMsg}`)
      }
    }

    // Calculate totals
    const successfulDownloads = results.filter(r => r.success).length
    const failedDownloads = results.filter(r => !r.success).length

    totalRows = results.reduce((sum, result) => {
      return sum + (result.rowCount || 0)
    }, 0)

    // Collect errors from individual downloads
    results.forEach(result => {
      if (!result.success && result.error) {
        errors.push(`${result.tableName}: ${result.error}`)
      }
    })

    const downloadTime = Date.now() - startTime

    console.log(`üèÅ Bulk download completed: ${successfulDownloads}/${tableNames.length} successful, ${totalRows} total rows, ${downloadTime}ms`)

    return {
      success: failedDownloads === 0,
      results,
      totalTables: tableNames.length,
      successfulDownloads,
      failedDownloads,
      totalRows,
      downloadTime,
      errors
    }
  }

  /**
   * Upload downloaded data to BigQuery
   */
  async uploadToBigQuery(
    tableName: BLNTableName,
    data: any[],
    options: {
      writeDisposition?: 'WRITE_TRUNCATE' | 'WRITE_APPEND' | 'WRITE_EMPTY'
      createTable?: boolean
    } = {}
  ): Promise<{ success: boolean; message?: string; error?: string }> {
    const { writeDisposition = 'WRITE_TRUNCATE', createTable = true } = options

    try {
      console.log(`üì§ Uploading ${tableName} to BigQuery: ${data.length} rows`)

      // Generate schema from data
      const schema = this.generateSchemaFromData(data, tableName)

      // Upload to BigQuery
      const result = await uploadToBigQuery({
        tableName,
        data,
        schema,
        writeDisposition
      })

      if (result.success) {
        console.log(`‚úÖ Successfully uploaded ${tableName} to BigQuery`)
      }

      return result

    } catch (error) {
      const errorMsg = `Failed to upload ${tableName} to BigQuery: ${error instanceof Error ? error.message : 'Unknown error'}`
      console.error(`‚ùå ${errorMsg}`)

      return {
        success: false,
        error: errorMsg
      }
    }
  }

  /**
   * Download and upload workflow (combines download + upload)
   */
  async downloadAndUpload(
    tableNames: BLNTableName[],
    options: {
      skipExisting?: boolean
      onProgress?: (table: string, status: 'downloading' | 'uploading' | 'completed' | 'failed') => void
    } = {}
  ): Promise<{
    success: boolean
    processed: string[]
    skipped: string[]
    failed: string[]
    totalRows: number
  }> {
    const { skipExisting = true, onProgress } = options

    const processed: string[] = []
    const skipped: string[] = []
    const failed: string[] = []
    let totalRows = 0

    for (const tableName of tableNames) {
      try {
        // Check if table already exists and has data
        if (skipExisting) {
          const existsCheck = await this.checkTableExists(tableName)
          if (existsCheck.exists && existsCheck.rowCount > 0) {
            console.log(`‚è≠Ô∏è Skipping ${tableName}: already exists with ${existsCheck.rowCount} rows`)
            skipped.push(tableName)
            onProgress?.(tableName, 'completed')
            continue
          }
        }

        // Download from BLN
        onProgress?.(tableName, 'downloading')
        const downloadResult = await this.downloadTable(tableName, { useCache: true })

        if (!downloadResult.success || !downloadResult.data) {
          failed.push(tableName)
          onProgress?.(tableName, 'failed')
          continue
        }

        // Upload to BigQuery
        onProgress?.(tableName, 'uploading')
        const uploadResult = await this.uploadToBigQuery(tableName, downloadResult.data)

        if (uploadResult.success) {
          processed.push(tableName)
          totalRows += downloadResult.rowCount || 0
          onProgress?.(tableName, 'completed')
        } else {
          failed.push(tableName)
          onProgress?.(tableName, 'failed')
        }

      } catch (error) {
        console.error(`‚ùå Error processing ${tableName}:`, error)
        failed.push(tableName)
        onProgress?.(tableName, 'failed')
      }
    }

    return {
      success: failed.length === 0,
      processed,
      skipped,
      failed,
      totalRows
    }
  }

  /**
   * Get information about available BLN tables
   */
  getAvailableTables(): typeof BLN_DATA_TABLES {
    return BLN_DATA_TABLES
  }

  /**
   * Clear the download cache
   */
  clearCache(pattern?: string): void {
    if (pattern) {
      const regex = new RegExp(pattern)
      for (const key of this.cache.keys()) {
        if (regex.test(key)) {
          this.cache.delete(key)
        }
      }
    } else {
      this.cache.clear()
    }
    console.log('üóëÔ∏è BLN cache cleared')
  }

  /**
   * Get cache statistics
   */
  getCacheStats(): {
    size: number
    keys: string[]
    totalMemory: number
  } {
    const keys = Array.from(this.cache.keys())
    const totalMemory = JSON.stringify([...this.cache.values()]).length

    return {
      size: this.cache.size,
      keys,
      totalMemory
    }
  }

  // Private helper methods

  /**
   * Simulate BLN API download (in production, this would make actual API calls)
   */
  private async simulateBLNDownload(tableName: BLNTableName): Promise<{
    success: boolean
    data?: any[]
    error?: string
  }> {
    try {
      // Simulate API delay
      await new Promise(resolve => setTimeout(resolve, 100 + Math.random() * 200))

      // Generate mock data based on table type
      const mockData = this.generateMockData(tableName)

      return {
        success: true,
        data: mockData
      }

    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Simulated download error'
      }
    }
  }

  /**
   * Generate mock data for testing (would be replaced with actual BLN API calls)
   */
  private generateMockData(tableName: BLNTableName): any[] {
    const baseRowCount = Math.floor(Math.random() * 1000) + 100

    switch (tableName) {
      case 'cvr_lobby_disclosure_cd':
        return Array(baseRowCount).fill(null).map((_, i) => ({
          FILING_ID: `FILING_${i + 1}`,
          FILER_NAML: `Filer ${i + 1}`,
          FIRM_NAME: `Firm ${i + 1}`,
          RPT_DATE: new Date(Date.now() - Math.random() * 365 * 24 * 60 * 60 * 1000).toISOString().split('T')[0],
          FROM_DATE: '2024-01-01',
          THRU_DATE: '2024-12-31',
          AMEND_ID: Math.floor(Math.random() * 10).toString()
        }))

      case 'lpay_cd':
        return Array(baseRowCount).fill(null).map((_, i) => ({
          FILING_ID: `FILING_${i + 1}`,
          LINE_ITEM: i + 1,
          EMPLR_NAML: `Employer ${i + 1}`,
          FEES_AMT: Math.floor(Math.random() * 50000),
          REIMB_AMT: Math.floor(Math.random() * 10000),
          ADVAN_AMT: Math.floor(Math.random() * 5000),
          PER_TOTAL: Math.floor(Math.random() * 100000),
          CUM_TOTAL: Math.floor(Math.random() * 500000),
          AMEND_ID: Math.floor(Math.random() * 10).toString()
        }))

      case 'latt_cd':
        return Array(baseRowCount).fill(null).map((_, i) => ({
          FILING_ID: `FILING_${i + 1}`,
          LINE_ITEM: i + 1,
          RECIP_NAML: `Association ${i + 1}`,
          PMT_DATE: new Date(Date.now() - Math.random() * 365 * 24 * 60 * 60 * 1000).toISOString().split('T')[0],
          AMOUNT: Math.floor(Math.random() * 25000),
          CUM_AMT: Math.floor(Math.random() * 100000),
          AMEND_ID: Math.floor(Math.random() * 10).toString()
        }))

      default:
        return Array(baseRowCount).fill(null).map((_, i) => ({
          id: i + 1,
          filing_id: `FILING_${i + 1}`,
          created_date: new Date().toISOString().split('T')[0],
          data_value: `Value ${i + 1}`
        }))
    }
  }

  /**
   * Generate BigQuery schema from BLN data
   */
  private generateSchemaFromData(data: any[], tableName: BLNTableName): any[] {
    if (!data || data.length === 0) {
      return []
    }

    const firstRow = data[0]
    const schema = Object.keys(firstRow).map(key => {
      const value = firstRow[key]
      let type = 'STRING' // default type

      if (typeof value === 'number') {
        type = Number.isInteger(value) ? 'INTEGER' : 'FLOAT'
      } else if (typeof value === 'boolean') {
        type = 'BOOLEAN'
      } else if (value && typeof value === 'string') {
        // CA Lobby specific date/timestamp patterns
        const dateRegex = /^\d{4}-\d{2}-\d{2}$/
        const timestampRegex = /^\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}/

        if (timestampRegex.test(value)) {
          type = 'TIMESTAMP'
        } else if (dateRegex.test(value)) {
          type = 'DATE'
        }
      }

      return {
        name: key,
        type,
        mode: 'NULLABLE'
      }
    })

    return schema
  }

  /**
   * Check if a table exists in BigQuery
   */
  private async checkTableExists(tableName: string): Promise<{
    exists: boolean
    rowCount: number
  }> {
    try {
      const query = `
        SELECT COUNT(*) as row_count
        FROM \`${process.env.GOOGLE_CLOUD_PROJECT_ID}.${process.env.BIGQUERY_DATASET}.${tableName}\`
      `

      const result = await executeQuery({ query })

      return {
        exists: result.success,
        rowCount: result.success ? result.data[0]?.row_count || 0 : 0
      }

    } catch (error) {
      return {
        exists: false,
        rowCount: 0
      }
    }
  }
}

/**
 * Factory function to create BLN client instance
 */
export function createBLNClient(config?: Partial<BLNConfig>): BLNClient {
  const apiKey = config?.apiKey || process.env.BLN_API_KEY
  const projectId = config?.projectId || process.env.BLN_PROJECT_ID || 'UHJvamVjdDo2MDVjNzdiYS0wODI4LTRlOTEtOGM3OC03ZjA4NGI2ZDEwZWE='

  if (!apiKey) {
    throw new Error('BLN API key is required. Set BLN_API_KEY environment variable or provide in config.')
  }

  if (!projectId) {
    throw new Error('BLN project ID is required. Set BLN_PROJECT_ID environment variable or provide in config.')
  }

  return new BLNClient({
    apiKey,
    projectId,
    ...config
  })
}

// Export utility functions
export { BLN_DATA_TABLES, type BLNTableName }